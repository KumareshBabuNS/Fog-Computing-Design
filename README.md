# Fog-Computing-Design
- The Cloud Services were extended to the users by installing fog servers which implements the functionality of cloud at the edge of the enterpriseâ€™s network. 
- Multi-Threading was used by servers to handle multiple client requests and the response time delay for the requests from IoT devices was decreased by 40% by distributing the service requests to fog servers.

Fog computing is a newly-introduced concept that aims to put the Cloud closer to the user for better quality of service (QoS). Fog computing is studied mostly in the context of Internet of Things (IoT) as it provides low latency, location awareness, support for wide-spread geographical distribution, and mobility support for IoT applications. Fog is not a substitute for but a powerful complement to the cloud.Fog nodes collaborate among each other and provide relevant cloud services such as computing, networking and storage to IoT devices. In this project, the main use of fog computing is to reduce the response time delay for requests coming from the IoT nodes.

When a fog node receives a request, depending on its current work load, it will either handle the request by itself or will forward it on. A request can be forwarded among the fog nodes at most Forward_Limit times. If a request is forwarded Forward_Limit many times and it cannot be served by the last fog node (due to its current work load), the node will forward the request to the cloud for processing. The node processing the request (either a fog node or the cloud) will directly send its response back to the IoT node.
